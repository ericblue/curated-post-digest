# AI Reddit Digest Configuration
# ================================
# Edit this file to customize your digest preferences

# Reddit API credentials (required for authenticated access)
# Get yours at: https://www.reddit.com/prefs/apps
# For unauthenticated access (rate limited), leave these empty
#
# Credentials can be provided via:
# 1. This config file (values below)
# 2. Environment variables: REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT
#    Environment variables take precedence over config file values
reddit:
  client_id: ""  # Or set REDDIT_CLIENT_ID environment variable
  client_secret: ""  # Or set REDDIT_CLIENT_SECRET environment variable
  user_agent: "AI-Reddit-Digest/1.0"  # Or set REDDIT_USER_AGENT environment variable

# Subreddits to monitor
# Add or remove subreddits as desired (without the r/ prefix)
subreddits:
  - ArtificialIntelligence
  - MachineLearning
  - LocalLLaMA
  - LLM
  - mlOps
  - ClaudeCode
  - ClaudeAI
  - LangChain
  - LlamaIndex
  - AIagents
  - OpenSourceAI
  - OpenAI
  - StableDiffusion
  - LocalLLM
  - AI_Agents
  - AgentsOfAI
  - ChatGPT
  - singularity

# Default time window (used if no CLI args provided)
# Format: ISO-8601 (e.g., 2025-01-01T00:00:00Z)
# Leave empty to default to "last 7 days ending now"
time_window:
  start: ""
  end: ""
  default_days: 7

# Fetch settings
fetch:
  # Maximum posts to fetch per subreddit
  max_posts_per_subreddit: 50
  # Maximum comments per post to fetch
  max_comments_per_post: 20
  # Minimum score threshold for posts (filters low-quality content)
  min_score: 5
  # Rate limit delay between requests (seconds)
  rate_limit_delay: 2

# Scoring weights for "interesting" heuristic
# These affect how posts are ranked (higher = more important)
scoring:
  # Heuristic scoring weights (used in compute_heuristic_score)
  # Weight for Reddit score (upvotes - downvotes)
  engagement_weight: 0.3
  # Weight for comment count
  comments_weight: 0.25
  # Weight for recency (fresher content scores higher)
  recency_weight: 0.2
  # Weight for content length (meaningful content)
  content_weight: 0.15
  # Weight for upvote ratio (quality indicator)
  ratio_weight: 0.1
  # Claude-assessed weights (used for final scoring by Claude)
  # Weight for novelty (Claude-assessed)
  novelty_weight: 0.25
  # Weight for relevance to AI/LLM topics (Claude-assessed)
  relevance_weight: 0.2

# Content length thresholds for scoring (in characters)
# These define the boundaries for content quality scoring
content_thresholds:
  very_short: 50    # Posts below this are low quality
  brief: 200        # Brief but acceptable
  good: 1000        # Ideal length
  substantial: 3000 # Long but not overwhelming

# Content length scores (0-1) for each threshold
content_scores:
  very_short: 0.3   # Too short
  brief: 0.5        # Acceptable
  good: 0.8         # Ideal
  substantial: 1.0  # Excellent
  wall_of_text: 0.7 # Too long

# Formatting limits for Claude processing
# These control how much text is sent to Claude (to reduce token usage)
formatting:
  # Maximum post body length to include
  max_selftext_length: 500
  # Maximum comment body length to include
  max_comment_body_length: 300
  # Number of top comments to include per post
  max_top_comments: 5

# Topics of personal interest (used by Claude for relevance scoring)
interests:
  - Large Language Models (LLMs)
  - Agentic AI and orchestration frameworks
  - Open-source AI tooling and infra
  - AI developer experience (DX)
  - Practical experimentation and prototypes
  - Local and self-hosted AI systems
  - Retrieval, RAG, and hybrid search
  - Reliability, evals, and failure modes
  - AI coding assistants and copilots
  - Agentic coding workflows (Claude Code, Cursor, etc.)
  
# Output settings
output:
  # Path to output report (relative to project root)
  report_path: "output/report.md"
  # Number of top posts to include in digest
  top_posts: 10
  # Include raw JSON data in output directory
  save_raw_data: true

# Claude settings (for summarization)
claude:
  # Model to use for summarization
  model: "claude-sonnet-4-20250514"
  # Maximum tokens for summary response
  max_tokens: 4096

